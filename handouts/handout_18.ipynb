{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 16 - Uncertainty Propagation: Polynomial Chaos I\n",
    "\n",
    "## Objectives\n",
    "\n",
    "+ Introduce quadrature rules in 1D and in particular nested quadrature rules.\n",
    "+ Expand quadrature rules in multiple dimensions using sparse grids.\n",
    "+ Solve stochastic dynamical systems using intrusive polynomial chaos.\n",
    "\n",
    "## Readings\n",
    "\n",
    "+ These notes.\n",
    "+ Sullivan, Chapter 9.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import scipy.stats as st\n",
    "import scipy\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk')\n",
    "import design\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import orthpol  # This is the package we will use to construct orthogonal polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadrature Rules\n",
    "\n",
    "### Simple Quadrature\n",
    "Consider the problem of evaluating an integral:\n",
    "$$\n",
    "I = \\int_a^b f(x) dx,\n",
    "$$\n",
    "where $a < b$.\n",
    "A *quadrature rule* is an approximation to that integral of the form:\n",
    "$$\n",
    "Q(f) = \\sum_{k=1}^nw_kf(x_k).\n",
    "$$\n",
    "The $x_k$'s are the *nodes* of the rule and the $w_k$'s are the *weights* of the rule.\n",
    "\n",
    "### Newton-Cotes rule (don't use it)\n",
    "Let's introduce this one by one.\n",
    "This rule is constructed as follows:\n",
    "\n",
    "+ Pick equidistant points in $[a,b]$:\n",
    "$$\n",
    "x_k = a + h k,\n",
    "$$\n",
    "for $k=0,\\dots,n+1$, where $h = \\frac{b-a}{n+1}$.\n",
    "\n",
    "+ Approximate $f$ using the [Lagrange polynomials](https://en.wikipedia.org/wiki/Lagrange_polynomial):\n",
    "$$\n",
    "f(x) \\approx \\sum_{k=1}^n f(x_k)\\ell_k(x).\n",
    "$$\n",
    "\n",
    "+ Approximate the integral by:\n",
    "$$\n",
    "Q_{nc}(f) = \\sum_{k=1}^n \\int_a^b\\ell_k(x)dx \\cdot f(x_k),\n",
    "$$\n",
    "i.e.,\n",
    "$$\n",
    "w_k = \\int_a^b\\ell_k(x)dx.\n",
    "$$\n",
    "\n",
    "In other words, the Newton-Cotes rule approximate the integral with the integral of the Lagrange polynomial that approximates the function based on these points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The function we will integrate\n",
    "f = lambda x: np.cos(x * 3)\n",
    "\n",
    "# Pick Newton-Cotes quadrature points\n",
    "nq = 3\n",
    "X = np.linspace(-1, 1, nq)\n",
    "\n",
    "# Get the Lagrange interpolating polynomial\n",
    "Lf = scipy.interpolate.lagrange(X, f(X))\n",
    "\n",
    "# Visualize the actual function and the Lagrange interpolating polynomial\n",
    "fig, ax = plt.subplots()\n",
    "x = np.linspace(-1, 1, 200)\n",
    "\n",
    "ax.plot(x, f(x))\n",
    "ax.fill_between(x, np.zeros(x.shape), f(x), alpha=0.25)\n",
    "ax.plot(x, Lf(x))\n",
    "ax.fill_between(x, np.zeros(x.shape), Lf(x), alpha=0.25)\n",
    "ax.plot(X, f(X), '.')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$f(x)$')\n",
    "ax.set_title('$n=%d$' % nq)\n",
    "plt.legend(['$f(x)$', '$L_f(x)$'], loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "+ Change the function above to $f(x) = H(x)$ (step function) and see that the Newton-Cotes rule has trouble approximating the integral no matter how many quadrature points you use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian quadrature (don't use it)\n",
    "\n",
    "This is just like the Newton-Cotes rule, but instead of equidistant nodes it uses nodes that are the zeros of the $n$-degree orthogonal polynomial with weight $w(x) = 1$.\n",
    "\n",
    "**Note:** You can generalize the Gaussian quadrature rule, for other weights.\n",
    "\n",
    "**Note:** Gaussian quadrature integrates exactly polynomials up to degree $2n + 1$ and there is no other quadrature rule with $n$ points that can do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The function we will integrate\n",
    "f = lambda x: np.cos(x * 3)\n",
    "\n",
    "\n",
    "# Pick Newton-Cotes quadrature points\n",
    "nq = 2\n",
    "# Get the roots of the nq - 1 degree polynomial with w[x] = 1 in [-1, 1] (Legendre)\n",
    "Xs, ws = scipy.special.roots_legendre(nq-1)\n",
    "# Get the roots of the nq degree polynomial\n",
    "X, w = scipy.special.roots_legendre(nq)\n",
    "\n",
    "# Get the Lagrange interpolating polynomial\n",
    "Lf = scipy.interpolate.lagrange(X, f(X))\n",
    "\n",
    "# Visualize the actual function and the Lagrange interpolating polynomial\n",
    "fig, ax = plt.subplots()\n",
    "x = np.linspace(-1, 1, 200)\n",
    "\n",
    "ax.plot(x, f(x))\n",
    "ax.fill_between(x, np.zeros(x.shape), f(x), alpha=0.25)\n",
    "ax.plot(x, Lf(x))\n",
    "ax.fill_between(x, np.zeros(x.shape), Lf(x), alpha=0.25)\n",
    "ax.plot(X, f(X), '.')\n",
    "#ax.plot(Xs, f(Xs), '.')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_title('$n=%d$' % nq)\n",
    "ax.set_ylabel('$f(x)$')\n",
    "plt.legend(['$f(x)$', '$L_f(x)$'], loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "+ Notice that the Gaussian quadrature nodes are not nested. Every time you increase the number of quadrature points, you get completely different nodes. This means that you cannot reuse the function evaluations you have seen so far.\n",
    "+ Change the function above to $f(x) = H(x)$ (step function) and see that the Gaussian quadrature rule has less trouble approximating the integral no matter how many quadrature points you use.\n",
    "+ Try $f(x) = \\cos(10 x) * \\exp\\{-(10x)^2/2\\}$ to see that some problems do persist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clenshaw-Curtis Quadrature\n",
    "\n",
    "We are looking for a quadrature rule with nested nodes. As we increase the number of points, we would like to be able to reuse the function evaluations.\n",
    "\n",
    "The derivation is quite involved, but it goes like this.\n",
    "Let us look at the case $a=-1, b=1$.\n",
    "First, we transform the integral by setting $x = \\cos\\theta$:\n",
    "$$\n",
    "\\int_{-1}^1 f(x)dx = \\int_0^\\pi f(\\cos\\theta)\\sin(\\theta)d\\theta.\n",
    "$$\n",
    "Then, expand the $f(\\cos\\theta)$ in cosine series:\n",
    "$$\n",
    "f(\\cos\\theta) = \\frac{a_0}{2} + \\sum_{k=1}^\\infty a_k \\cos(k\\theta),\n",
    "$$\n",
    "where\n",
    "$$\n",
    "a_k = \\frac{2}{\\pi}\\int_0^\\pi f(\\cos\\theta)\\cos(k\\theta)d\\theta.\n",
    "$$\n",
    "From this, we get:\n",
    "$$\n",
    "\\int_0^\\pi f(\\cos\\theta)\\sin\\theta d\\theta = a_0 + \\sum_{k=1}^\\infty\\frac{2a_k}{1 - (2k)^2}.\n",
    "$$\n",
    "Now, using the [Nyquist-Shannon sampling theorem](https://en.wikipedia.org/wiki/Nyquistâ€“Shannon_sampling_theorem) from signal processing, we see that we can evaluate the coefficients $a_k$ for $k\\le n$ **exactly** if we evaluate $f(\\cos\\theta)$ at $n+1$ equidistant nodes $\\theta_j = \\frac{j\\pi}{n}, j=0,\\dots,n$. It is:\n",
    "$$\n",
    "a_k = \\frac{2}{n}\\left((-1)^k\\frac{f(-1)}{2} + \\frac{f(1)}{2} + \\sum_{j=1}^{n-1}f\\left(\\cos\\frac{j\\pi}{n}\\right)\\cos\\frac{kj\\pi}{n}\\right).\n",
    "$$\n",
    "So, we see that the nodes are:\n",
    "$$\n",
    "x_j = \\cos\\frac{j\\pi}{n},\n",
    "$$\n",
    "$j=0,1,\\dots,n$ and that they are indeed nested (double $n$).\n",
    "To get the weigths, you re-arrange terms and you try to identify the $w_j$'s.\n",
    "\n",
    "**Note:** Clenshaw-Curtis quadrature integrates exactly polynomials up to degree $n+1$.\n",
    "\n",
    "**Note:** We will only be using the Clenshaw-Curtis quadrature from now on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The function we will integrate\n",
    "#f = lambda x: np.cos(x * 5)\n",
    "\n",
    "# Pick Newton-Cotes quadrature points\n",
    "fig, ax = plt.subplots()\n",
    "for l in [4, 3, 2, 1]:\n",
    "    X, w = design.sparse_grid(1, l, rule='CC') # CC = Clenshaw-Curtis\n",
    "    ax.plot(X, np.zeros(X.shape[0]), '.')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$f(x)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Verify that the Legendre Polynomials are Orthogonal\n",
    "\n",
    "Let $X\\sim\\mathcal{U}(-1, 1)$. The orthogonal polynomials in this case are known as the [Laguerre polynomials](https://en.wikipedia.org/wiki/Laguerre_polynomials).\n",
    "They are known analytically.\n",
    "The first few are:\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "\\phi_1(x) &=& 1,\\\\\n",
    "\\phi_2(x) &=& x,\\\\\n",
    "\\phi_3(x) &=& \\frac{1}{2}\\left(3x^2 -1\\right).\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "We constructed them we ``orthpol`` in the previous handout.\n",
    "Let's verify now that they are also orthogonal by using a CC quadrature rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, instead of the random variable let's use the the p(x) derectly\n",
    "p = lambda x: 0.5\n",
    "# The maximum polynomial degree you want\n",
    "degree = 4\n",
    "# Construct the orthogonal polynomials\n",
    "Phi_set = orthpol.OrthogonalPolynomial(degree,\n",
    "                                       wf=p,    # The weight function (or pdf)\n",
    "                                       left=-1, # The left bound\n",
    "                                       right=1  # The right bound\n",
    "                                       )\n",
    "\n",
    "# Plot them\n",
    "fig, ax = plt.subplots()\n",
    "# Evaluate the orhtogonal polynomials on all these x's\n",
    "x = np.linspace(-1, 1, 200)\n",
    "phi_x = Phi_set(x)    # 200 x (degree + 1)\n",
    "# Plot each one of them\n",
    "ax.plot(x, phi_x);\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$\\phi_i(x)$')\n",
    "ax.set_title('$X\\sim\\mathcal{U}(-1, 1)$: Legendre Polynomials')\n",
    "plt.legend(['$\\phi_{%d}(x)$' % i for i in range(1, degree + 1)], loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, w = design.sparse_grid(1, 5, 'CC') # w(x) = 1 and x in [-1, 1] for this one\n",
    "w = w / 2.  # We need to normalize the weights\n",
    "phi_q = Phi_set(X)\n",
    "for i in range(phi_q.shape[1]):\n",
    "    for j in range(i, phi_q.shape[1]):\n",
    "        print '<%d, %d> \\t= %1.3f' % (i, j, np.sum(w * phi_q[:, i] * phi_q[:, j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Arbitrary Expecations with the CC Quadrature Rule\n",
    "\n",
    "The CC rule can only evaluate integrals of the form $\\int_{-1}^1f(x)dx$.\n",
    "Let's see how we can extend it to the evaluation of arbitrary expectations of the form:\n",
    "$$\n",
    "\\mathbb{E}[f(X)]:=\\int_{-\\infty}^\\infty f(x)p(x)dx.\n",
    "$$\n",
    "Let $F(x)$ be the CDF of $p(x)$ and define the transformation:\n",
    "$$\n",
    "z = 2F(x) - 1.\n",
    "$$\n",
    "The inverse, of course, is:\n",
    "$$\n",
    "x = F^{-1}\\left(\\frac{z+1}{2}\\right).\n",
    "$$\n",
    "Notice that $z\\in [-1,1]$.\n",
    "We also have that:\n",
    "$$\n",
    "dz = 2F'(x)dx = 2p(x)dx\n",
    "$$\n",
    "and that as $x\\rightarrow \\pm \\infty$ we get that $z\\rightarrow\\pm 1$.\n",
    "Therefore, we can rewrite the expcation as:\n",
    "$$\n",
    "\\mathbb{E}[f(X)] = \\frac{1}{2}\\int_{-1}^1 f\\left(F^{-1}\\left(\\frac{z+1}{2}\\right)\\right)dz\n",
    "$$\n",
    "Now, if $z_k$ and $v_k$, $k=1,\\dots,n$ are nodes and weights for the common CC rule, we get the following quadrature rule for our special case:\n",
    "$$\n",
    "w_k = \\frac{1}{2}v_k,\n",
    "$$\n",
    "and\n",
    "$$\n",
    "x_k = F^{-1}\\left(\\frac{z_k+1}{2}\\right).\n",
    "$$\n",
    "\n",
    "Let's try it out by testing the Hermite polynomials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: The Standard Normal and the Hermite Polynomials\n",
    "\n",
    "Let $X\\sim\\mathcal{N}(0,1)$. The orthogonal polynomials in this case are known as the [Hermite polynomials](https://en.wikipedia.org/wiki/Hermite_polynomials).\n",
    "They are known analytically.\n",
    "The first few are:\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "\\phi_1(x) &=& 1,\\\\\n",
    "\\phi_2(x) &=& x,\\\\\n",
    "\\phi_3(x) &=& x^2 - 1,\\\\\n",
    "\\phi_4(x) &=& x^3 - 3x,\\\\\n",
    "\\phi_5(x) &=& x^4 - 6x^2 + 3.\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The random variable you wish to consider\n",
    "X = st.norm()\n",
    "# The maximum polynomial degree you want\n",
    "degree = 3\n",
    "# Construct the orthogonal polynomials\n",
    "Phi_set = orthpol.OrthogonalPolynomial(degree, X, ncap=1000)\n",
    "\n",
    "# Plot the probability density\n",
    "fig, ax = plt.subplots()\n",
    "x = np.linspace(-3, 3, 200)\n",
    "ax.plot(x, X.pdf(x))\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$p(x)$')\n",
    "\n",
    "# Plot them\n",
    "fig, ax = plt.subplots()\n",
    "# Evaluate the orhtogonal polynomials on all these x's\n",
    "phi_x = Phi_set(x)    # 200 x (degree + 1)\n",
    "# Plot each one of them\n",
    "ax.plot(x, phi_x);\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$\\phi_i(x)$')\n",
    "ax.set_title('$X\\sim\\mathcal{N}(0,1)$: Hermite Polynomials')\n",
    "plt.legend(['$\\phi_{%d}(x)$' % i for i in range(0, degree + 1)], loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z, v = design.sparse_grid(1, 8, 'F1') # We do not use CC because it is closed (includes -1, 1) - Fejer 1 is open\n",
    "X = st.norm.ppf(0.5 * (Z + 1.))\n",
    "w = v / 2\n",
    "phi_q = Phi_set(X)\n",
    "for i in range(phi_q.shape[1]):\n",
    "    for j in range(i, phi_q.shape[1]):\n",
    "        print '<%d, %d> \\t= %1.3f' % (i, j, np.sum(w * phi_q[:, i] * phi_q[:, j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: The Exponential and the Laguerre Polynomials\n",
    "\n",
    "Let $X\\sim\\mathcal{E}(1)$. The orthogonal polynomials in this case are known as the [Laguerre polynomials](https://en.wikipedia.org/wiki/Laguerre_polynomials).\n",
    "They are known analytically.\n",
    "The first few are:\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "\\phi_1(x) &=& 1,\\\\\n",
    "\\phi_2(x) &=& -x + 1,\\\\\n",
    "\\phi_3(x) &=& \\frac{1}{2}\\left(x^2 - 4x + 2\\right).\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The random variable you wish to consider\n",
    "X = st.expon()\n",
    "# The maximum polynomial degree you want\n",
    "degree = 3\n",
    "# Construct the orthogonal polynomials\n",
    "Phi_set = orthpol.OrthogonalPolynomial(degree, X)\n",
    "\n",
    "# Plot the probability density\n",
    "fig, ax = plt.subplots()\n",
    "x = np.linspace(0, 5, 200)\n",
    "ax.plot(x, X.pdf(x))\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$p(x)$')\n",
    "\n",
    "# Plot them\n",
    "fig, ax = plt.subplots()\n",
    "# Evaluate the orhtogonal polynomials on all these x's\n",
    "phi_x = Phi_set(x)    # 200 x (degree + 1)\n",
    "# Plot each one of them\n",
    "ax.plot(x, phi_x);\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$\\phi_i(x)$')\n",
    "ax.set_title('$X\\sim\\mathcal{E}(1)$: Laguerre Polynomials')\n",
    "plt.legend(['$\\phi_{%d}(x)$' % i for i in range(1, degree + 1)], loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Z, v = design.sparse_grid(1, 9, 'F1') # Again F1 isntead of CC\n",
    "w = v / 2.\n",
    "X = st.expon.ppf(0.5 * (Z + 1.))\n",
    "phi_q = Phi_set(X)\n",
    "for i in range(phi_q.shape[1]):\n",
    "    for j in range(i, phi_q.shape[1]):\n",
    "        print '<%d, %d> \\t= %1.3f' % (i, j, np.sum(w * phi_q[:, i] * phi_q[:, j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: We can do it for any probability density\n",
    "\n",
    "We can construct orthonormal for any random variable $X$.\n",
    "Let's do it for a mixture of Gaussians:\n",
    "$$\n",
    "p(x) = \\pi_1 \\mathcal{N}(x|\\mu_1,\\sigma_1^2) + \\pi_2\\mathcal{N}(x|\\mu_2,\\sigma_2^2),\n",
    "$$\n",
    "for $\\pi_1 + \\pi_2 = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The random variable you wish to consider\n",
    "X1 = st.norm(loc=-1, scale=0.4)\n",
    "pi_1 = 0.2\n",
    "X2 = st.norm(loc=+1, scale=0.4)\n",
    "pi_2 = 0.8\n",
    "\n",
    "p = lambda x: pi_1 * X1.pdf(x) + pi_2 * X2.pdf(x)\n",
    "\n",
    "class MGRV(st.rv_continuous):\n",
    "    \n",
    "    def _pdf(self, x):\n",
    "        return p(x)\n",
    "\n",
    "mgrv = MGRV()\n",
    "    \n",
    "# The maximum polynomial degree you want\n",
    "degree = 5\n",
    "# Construct the orthogonal polynomials\n",
    "Phi_set = orthpol.OrthogonalPolynomial(degree, wf=mgrv.pdf, left=-np.inf, right=np.inf, ncap=5000)\n",
    "Phi_set.normalize()\n",
    "\n",
    "# Plot the probability density\n",
    "fig, ax = plt.subplots()\n",
    "x = np.linspace(-2, 2, 200)\n",
    "ax.plot(x, mgrv.pdf(x))\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$p(x)$')\n",
    "\n",
    "# Plot them\n",
    "fig, ax = plt.subplots()\n",
    "# Evaluate the orhtogonal polynomials on all these x's\n",
    "phi_x = Phi_set(x)    # 200 x (degree + 1)\n",
    "# Plot each one of them\n",
    "ax.plot(x, phi_x);\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$\\phi_i(x)$')\n",
    "ax.set_title('$X\\sim\\sum_i\\pi_i\\mathcal{N}(\\mu_i,\\sigma_i)$: Whatever Polynomials')\n",
    "plt.legend(['$\\phi_{%d}(x)$' % i for i in range(0, degree + 1)], loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For this one we need a quadrature rule in (-infty, +infty) with w(x) = the pdf of the mixture\n",
    "# Let's use a rule in (-1, 1) (the rule is open if the boundaries are not included) and transform it to (-infty, infty)\n",
    "Z, v = design.sparse_grid(1, 5, 'F1') # Fejer 2, open, fully nested, w(x) = 1 and x in (-1, 1)\n",
    "X = mgrv.ppf(0.5 * (Z + 1))\n",
    "w = v / 2.\n",
    "\n",
    "#X = st.norm.ppf(0.5 * (Z + 1))\n",
    "#w = v / (2. * st.norm.pdf(X)) * p(X)\n",
    "plt.plot(X, np.zeros(X.shape[0], ), '.')\n",
    "plt.plot(x, mgrv.pdf(x))\n",
    "\n",
    "#help(st.norm.ppf)\n",
    "#w = w / 2.  # We need to normalize the weights\n",
    "phi_q = Phi_set(X)\n",
    "for i in range(phi_q.shape[1]):\n",
    "    for j in range(i, phi_q.shape[1]):\n",
    "        print '<%d, %d> \\t= %1.3f' % (i, j, np.sum(w * phi_q[:, i] * phi_q[:, j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More 1D Quadrature Rules\n",
    "\n",
    "There are many more quadrature rules with various properties.\n",
    "Some of the ones you can use from ``py-design`` are described [here](http://people.sc.fsu.edu/~jburkardt/f_src/sparse_grid_mixed_dataset/sparse_grid_mixed_dataset.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(design.sparse_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadrature Rules in High-Dimensions\n",
    "\n",
    "\n",
    "### Tensor Products of Quadrature Rules\n",
    "The simplest approach to create high-dimensional quadrature rules is to take the tensor product of 1D ones.\n",
    "For example, suppose you have a quadrature rule in 1D:\n",
    "$$\n",
    "Q^{(1)}(f) = \\sum_{k=1}^n w_k f(x_k).\n",
    "$$\n",
    "The *tensor* product of $Q^{(1)}$ with itself is the 2D quadrature rule:\n",
    "$$\n",
    "Q^{(2)} = Q^{(1)}\\otimes Q^{(1)}\n",
    "$$\n",
    "defined by:\n",
    "$$\n",
    "Q^{(2)}(f) = \\left(Q^{(1)}\\otimes Q^{(1)}\\right)(f) = \\sum_{i=1}^n\\sum_{j=1}^n w_i w_j f(x_i, x_j).\n",
    "$$\n",
    "The tensor product can be generalized between any two quadrature rules in arbitrary dimensions.\n",
    "\n",
    "**Note:** The number of nodes in the tensor product of two quadrature rules grows exponential with the dimensionality (*curse of dimensionality*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import izip\n",
    "\n",
    "level = 4\n",
    "Z, v = design.sparse_grid(1, level, 'CC')\n",
    "\n",
    "# Make the tensor rule\n",
    "nq = Z.shape[0]\n",
    "Z21, Z22 = np.meshgrid(Z, Z)\n",
    "Z2 = np.hstack([Z21.flatten()[:, None], Z22.flatten()[:, None]])\n",
    "\n",
    "# Plot it\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(Z2[:, 0], Z2[:, 1], '.')\n",
    "ax.set_title('Tensor Product Rule')\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Grid Quadrature\n",
    "\n",
    "You can build a sparse grid (SG) quadrature out of any 1D quadrature rule $Q_\\ell^{(1)}$ of level $\\ell$.\n",
    "The only restriction is that $Q_\\ell^{(1)}$ must be nested, in the sense that all that nodes that are in $Q_{\\ell}^{(1)}$ must be included in $Q_{\\ell+1}^{(1)}$.\n",
    "The whole point is to get a rule in which the number of nodes does not grow as fast as in a tensor product.\n",
    "\n",
    "The construction of high-dimensional sparse grids is given by the *Smolyak quadrature formula*:\n",
    "$$\n",
    "Q_\\ell^{(d)}(f) := \\left(\\sum_{i=1}^\\ell\\left(Q_i^{(1)} - Q_{i-1}^{(1)}\\right)\\otimes Q_{\\ell-i+1}^{(d-1)}\\right)(f).\n",
    "$$\n",
    "Understanding this formula is beyond what we want to do.\n",
    "Let's just look at how sparse grids look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "level = 6\n",
    "count = 0\n",
    "for i in range(level):\n",
    "    Z, v = design.sparse_grid(2, i, 'CC')\n",
    "    ax.plot(Z[count:, 0], Z[count:, 1], '.', color=sns.color_palette()[i], label='$L=%d$' % (i + 1))\n",
    "    count = Z.shape[0]\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')\n",
    "ax.set_title('Max level = %d' % level);\n",
    "#plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse grids grow much slower than tensor products. See below how the number of nodes grows as a function of the space dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "max_dim = 20\n",
    "for level in range(1, 3):\n",
    "    Z1, _ = design.sparse_grid(1, level, 'CC')\n",
    "    sparse_grid_num_nodes = []\n",
    "    tensor_num_nodes = []\n",
    "    for d in range(1, max_dim + 1):\n",
    "        Z, _ = design.sparse_grid(d, level, 'CC')\n",
    "        sparse_grid_num_nodes.append(Z.shape[0])\n",
    "        tensor_num_nodes.append(Z1.shape[0] ** d)\n",
    "    ax.semilogy(range(1, max_dim + 1), sparse_grid_num_nodes, '-.', label='Sparse grid ($L=%d$)' % level)\n",
    "    ax.semilogy(range(1, max_dim + 1), tensor_num_nodes, '--.', label='Tensor product ($L=%d)$' % level)\n",
    "ax.set_xlabel('$d$')\n",
    "ax.set_ylabel('Number of quadrature points')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Multidimensional Orthogonal Polynomials\n",
    "\n",
    "Let's construct orthogonal polynomials for a random vector:\n",
    "$$\n",
    "X = (X_1,X_2),\n",
    "$$\n",
    "where\n",
    "$$\n",
    "X_1\\sim\\mathcal{U}(-1,1),\n",
    "$$\n",
    "and\n",
    "$$\n",
    "X_2\\sim\\mathcal{U}(-1, 1).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X1 = st.uniform(loc=-1, scale=2)\n",
    "X2 = st.uniform(loc=-1, scale=2)\n",
    "X = (X1, X2)\n",
    "dim = len(X)\n",
    "\n",
    "# The maximum polynomial degree you want\n",
    "degree = 4\n",
    "# Construct the orthogonal polynomials - See documentation for more ways to do create\n",
    "# multi-dimensional polynomials\n",
    "Phi_set = orthpol.ProductBasis(X, degree=degree)\n",
    "\n",
    "Z, v = design.sparse_grid(dim, 4, 'CC') # Gauss-Hermite which uses w(x) = e^{-x^T x} - need to scale:\n",
    "X = Z\n",
    "w = v / (2 ** dim)\n",
    "\n",
    "phi_q = Phi_set(Z)\n",
    "for i in range(phi_q.shape[1]):\n",
    "    for j in range(i, phi_q.shape[1]):\n",
    "        print '<%d, %d>\\t= %1.2f' % (i, j, np.sum(w * phi_q[:, i] * phi_q[:, j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Multidimensional Orthogonal Polynomials\n",
    "\n",
    "Let's construct orthogonal polynomials for a random vector:\n",
    "$$\n",
    "X = (X_1,X_2),\n",
    "$$\n",
    "where\n",
    "$$\n",
    "X_1\\sim\\mathcal{N}(0,1),\n",
    "$$\n",
    "and\n",
    "$$\n",
    "X_2\\sim\\mathcal{N}(0, 1).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X1 = st.norm()\n",
    "X2 = st.norm()\n",
    "X = (X1, X2)\n",
    "dim = len(X)\n",
    "\n",
    "# The maximum polynomial degree you want\n",
    "degree = 4\n",
    "# Construct the orthogonal polynomials - See documentation for more ways to do create\n",
    "# multi-dimensional polynomials\n",
    "Phi_set = orthpol.ProductBasis(X, degree=degree)\n",
    "\n",
    "Z, v = design.sparse_grid(2, 5, 'GH') # Gauss-Hermite which uses w(x) = e^{-x^T x} - need to scale:\n",
    "X = Z * np.sqrt(2.)\n",
    "w = v / np.sqrt(np.pi ** dim)\n",
    "\n",
    "phi_q = Phi_set(X)\n",
    "for i in range(phi_q.shape[1]):\n",
    "    for j in range(i, phi_q.shape[1]):\n",
    "        print '<%d, %d>\\t= %1.2f' % (i, j, np.sum(w * phi_q[:, i] * phi_q[:, j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intrusive Uncertainty Propagation Methods: Dynamical Systems\n",
    "\n",
    "Let $X$ be a random vector with probability density $p(x)$.\n",
    "Let $\\phi_1,\\phi_2,\\dots$ be an orthonormal basis with respect to $p(x)$.\n",
    "Consider the stochastic dynamical system:\n",
    "Consider the $m$-dimensional dynamical system:\n",
    "$$\n",
    "\\frac{dy}{dt} = g(y;X),\n",
    "$$\n",
    "with initial conditions\n",
    "$$\n",
    "y(0) = y_0(X).\n",
    "$$\n",
    "\n",
    "Assume that the solution $y(t;x)$ is square integrable.\n",
    "Then, at a given timestep $t$, we take the solution and we expand it in the polynomial basis:\n",
    "$$\n",
    "y(t;x) = \\sum_{i=1}^\\infty c_i(t)\\phi_i(x).\n",
    "$$\n",
    "Note that the coefficients are functions of time.\n",
    "According to our discussion above, if you find these $c_i(t)$'s, the expected value of the dynamical system will be:\n",
    "$$\n",
    "\\mathbb{E}[y(t;X)] = c_1(t),\n",
    "$$\n",
    "and the variance will be:\n",
    "$$\n",
    "\\mathbb{V}[y(t;X)] = \\sum_{i=2}^\\infty c_i^2(t).\n",
    "$$\n",
    "\n",
    "### Derivation of the Dynamical System for the Polynomial Coefficients\n",
    "We will derive a dynamical system that the coefficients must satisfy.\n",
    "At the initial conditions we have:\n",
    "$$\n",
    "y(0;x) = y_0(x)\\Rightarrow \\sum_{i=1}^\\infty c_i(0)\\phi_i(x) = y_0(x),\n",
    "$$\n",
    "so we get that:\n",
    "$$\n",
    "c_i(0) = \\langle \\phi_i, y_0\\rangle.\n",
    "$$\n",
    "\n",
    "Now, take the derivative of $y(t;x)$ with respect to $t$:\n",
    "$$\n",
    "\\frac{dy}{dt} = \\sum_{i=1}^\\infty \\frac{dc_i}{dt}\\phi_i(x).\n",
    "$$\n",
    "This looks good, but notice that $\\frac{dy}{dt} = g(y;x)$ is also a function of $y(t; x)$.\n",
    "We must think of $g(y;x)$ as a function of $x$ with a fixed $y$.\n",
    "Then we get:\n",
    "$$\n",
    "\\frac{dc_i}{dt} = \\left\\langle \\phi_i, g\\left(\\sum_{j=1}^\\infty c_j\\phi_j, \\cdot\\right)\\right\\rangle.\n",
    "$$\n",
    "\n",
    "Thus, the dynamical systme that we need to solve to find the coefficents at any time is the following:\n",
    "$$\n",
    "\\frac{dc_i}{dt} = \\left\\langle \\phi_i, g\\left(\\sum_{j=1}^\\infty c_j\\phi_j, \\cdot\\right)\\right\\rangle,\n",
    "$$\n",
    "with initial conditions:\n",
    "$$\n",
    "c_i(0) = \\langle \\phi_i, y_0\\rangle,\n",
    "$$\n",
    "for $i=1,2,\\dots$ (in practice, we truncate at a given order).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 7: Dynamical System with Uncertain Parameters\n",
    "Take the random vector:\n",
    "$$\n",
    "X = (X_1, X_2),\n",
    "$$\n",
    "and assume that the components are independent Gaussian:\n",
    "$$\n",
    "X_i \\sim \\mathcal{N}(\\mu_i, \\sigma_i^2).\n",
    "$$\n",
    "So, for the full random vector we have a mean:\n",
    "$$\n",
    "\\mu = (\\mu_1, \\mu_2),\n",
    "$$\n",
    "and a covariance matrix:\n",
    "$$\n",
    "\\Sigma = \\operatorname{diag}(\\sigma_1^2,\\sigma_2^2).\n",
    "$$\n",
    "\n",
    "Consider the ODE:\n",
    "  \\begin{align*}\n",
    "    &\\dot{y} = \\frac{d y(t)}{dt} =-X_1y(t) \\equiv g(y,X),\\\\\n",
    "    &\\qquad y(0) = X_2 \\equiv y_0(X).\n",
    "  \\end{align*}\n",
    "\n",
    "Let's see if we can carry out the inner produces that are required for setting up the dynamical system for the polynomial coefficients:\n",
    "$$\n",
    "c_i(0) = \\langle \\phi_i, y_0\\rangle = \\langle \\phi_i, x_2\\rangle.\n",
    "$$\n",
    "\n",
    "We should be able to do this numerically with some simple quadrature rule $\\{(w_q,x_q)\\}_{q=1}^{N_q}$:\n",
    "$$\n",
    "c_{i0} = \\langle \\phi_i, y_0\\rangle \\approx \\sum_{q=1}^{N_q}w_q \\phi_i(x_q)x_{q,2}.\n",
    "$$\n",
    "\n",
    "The other integrals that we need are:\n",
    "$$\n",
    "\\langle \\phi_i, g\\rangle = \\langle \\phi_i, -x_1 \\sum_{j=1}^\\infty c_j \\phi_j\\rangle = -\\sum_{j=1}^\\infty c_j \\langle \\phi_i, x_1\\phi_j\\rangle.\n",
    "$$\n",
    "We can approximate all the integrals inside the summation by:\n",
    "$$\n",
    "A_{ij} = \\langle \\phi_i, x_1\\phi_j\\rangle \\approx \\sum_{q=1}^{N_q}w_q\\phi_i(x_q)x_{q1}\\phi_j(x_q). \n",
    "$$\n",
    "\n",
    "With these definitions, the dynamical system that we need to solve is:\n",
    "$$\n",
    "\\frac{dc_i}{dt} = -\\sum_{j=1}^\\infty c_j A_{ij},\n",
    "$$\n",
    "with initial conditions:\n",
    "$$\n",
    "c_i(0) = c_{i0},\n",
    "$$\n",
    "for $i=1,2,\\dots$ (we will truncate).\n",
    "\n",
    "Let's do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION WITH ORTHOGONAL POLYNOMIALS\n",
    "\n",
    "# Construct the random variables - It is not very stable to work with the original \n",
    "# random varibales (too little uncertainty).\n",
    "# So, we work with scaled versions.\n",
    "mu1 = 0.05; sigma1 = 0.01\n",
    "sX1 = st.norm()\n",
    "mu2 = 8; sigma2 = 0.01\n",
    "sX2 = st.norm()\n",
    "sX = (sX1, sX2)\n",
    "mu = np.array([mu1, mu2])\n",
    "Sigma = np.diag([sigma1 ** 2, sigma2 ** 2])\n",
    "\n",
    "# Construct the orthonormal polynomials\n",
    "degree = 3\n",
    "Phi_set = orthpol.ProductBasis((sX1, sX2), degree=degree, ncap=1000)\n",
    "Phi_set.polynomials[0].normalize()\n",
    "Phi_set.polynomials[1].normalize()\n",
    "# Get a quadrature rule - we will talk about the quadrature rules in Lecture 17.\n",
    "Z, v = design.sparse_grid(2, 5, 'GH') # Gauss-Hermite which uses w(x) = e^{-x^T x} - need to scale:\n",
    "sXq = Z * np.sqrt(2.)\n",
    "w = v / np.sqrt(np.pi ** dim)\n",
    "Xq = np.ndarray(sXq.shape)\n",
    "Xq[:, 0] = sXq[:, 0] * sigma1 + mu1\n",
    "Xq[:, 1] = sXq[:, 1] * sigma2 + mu2\n",
    "\n",
    "# Evaluate the integrals needed for defining the dynamical system\n",
    "# Evaluate the orthogonal polynomials on the quadrature points\n",
    "phi_q = Phi_set(sXq)\n",
    "c0 = np.einsum('q,q,qj->j', w, Xq[:, 1], phi_q)\n",
    "# Evaluate the integrals giving rise to the matrix A\n",
    "A = np.einsum('q,q,qi,qj->ij', w, Xq[:, 0], phi_q, phi_q)\n",
    "\n",
    "# Define the dynamical system\n",
    "pc_rhs = lambda c, t: -np.dot(A, c)\n",
    "\n",
    "# Solve the system\n",
    "t = np.linspace(0, 100, 500)\n",
    "c = scipy.integrate.odeint(pc_rhs, c0, t)\n",
    "\n",
    "# Extract the mean\n",
    "y_pc_m = c[:, 0]\n",
    "\n",
    "# Extract the variance\n",
    "y_pc_v = np.sum(c[:, 1:] ** 2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION WITH SAMPLING (FOR COMPARISON)\n",
    "import scipy.integrate\n",
    "\n",
    "class Ex1Solver(object):\n",
    "    \"\"\"\n",
    "    An object that can solver the afforementioned ODE problem.\n",
    "    It will work just like a multivariate function.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, nt=100, T=5):\n",
    "        \"\"\"\n",
    "        This is the initializer of the class.\n",
    "        \n",
    "        Arguments:\n",
    "            nt - The number of timesteps.\n",
    "            T  - The final time.\n",
    "        \"\"\"\n",
    "        self.nt = nt\n",
    "        self.T = T\n",
    "        self.t = np.linspace(0, T, nt) # The timesteps on which we will get the solution\n",
    "        # The following are not essential, but they are convenient\n",
    "        self.num_input = 2             # The number of inputs the class accepts\n",
    "        self.num_output = nt           # The number of outputs the class returns\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        This special class method emulates a function call.\n",
    "        \n",
    "        Arguments:\n",
    "            x - A 1D numpy array with 2 elements. This represents the stochastic input x = (x1, x2).\n",
    "        \"\"\"\n",
    "        # The dynamics of the adjoint z = y, dy/dx1, dy/dx2\n",
    "        def g(z, t, x):\n",
    "            return -x[0] * z[0], -x[0] * z[1] - z[0], -x[0] * z[2]\n",
    "        # The initial condition\n",
    "        y0 = (x[1], 0, 1)\n",
    "        # We are ready to solve the ODE\n",
    "        y = scipy.integrate.odeint(g, y0, self.t, args=(x,))\n",
    "        return y\n",
    "    \n",
    "import design\n",
    "num_lhs = 10000\n",
    "X_lhs = design.latin_center(num_lhs, 2) # These are uniformly distributed - Turn them to standard normal\n",
    "X_samples = mu + np.dot(st.norm.ppf(X_lhs), np.sqrt(Sigma))\n",
    "solver = Ex1Solver(nt=500, T=100)\n",
    "s = 0.\n",
    "s2 = 0.\n",
    "for x in X_samples:\n",
    "    y = solver(x)[:, 0]\n",
    "    s += y\n",
    "    s2 += y ** 2\n",
    "y_mu_lhs = s / num_lhs\n",
    "y_var_lhs = s2 / num_lhs - y_mu_lhs ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make the figure\n",
    "fig1, ax1 = plt.subplots()\n",
    "\n",
    "# Plot the mean and compare to LHS\n",
    "ax1.plot(solver.t, y_mu_lhs, color=sns.color_palette()[0], label='LHS mean ($n=%d$)' % num_lhs)\n",
    "ax1.plot(t, y_pc_m, '--', color=sns.color_palette()[1], label=r'PC mean ($\\rho=%d$)' % degree)\n",
    "ax1.set_xlabel('$t$')\n",
    "ax1.set_ylabel('$\\mu(t)$', color=sns.color_palette()[0])\n",
    "ax1.tick_params('y', colors=sns.color_palette()[0])\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Plot variance and compare to LHS\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(solver.t, y_var_lhs, color=sns.color_palette()[2], label='LHS variance ($n=%d$)' % (num_lhs))\n",
    "ax2.plot(solver.t, y_pc_v, '--', color=sns.color_palette()[3], label=r'PC variance ($\\rho=%d$)' % degree)\n",
    "ax2.set_ylabel('$\\sigma^2(t) = k(t, t)$', color=sns.color_palette()[2])\n",
    "ax2.tick_params('y', colors=sns.color_palette()[2])\n",
    "plt.legend(loc='center right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's do 95% intervals\n",
    "s = np.sqrt(y_pc_v)\n",
    "l = y_pc_m - 2 * s\n",
    "u = y_pc_m + 2 * s\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, y_pc_m)\n",
    "ax.fill_between(t, l, u, alpha=0.25)\n",
    "ax.set_xlabel('$t$')\n",
    "ax.set_ylabel('$y(t)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's take some sample paths\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('$t$')\n",
    "ax.set_ylabel('$y(t)$')\n",
    "for _ in range(5):\n",
    "    s_x_s = np.random.randn(2)\n",
    "    y_s = np.dot(c, Phi_set(s_x_s[None, :]).T)\n",
    "    ax.plot(t, y_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "+ Repeat the analysis with higher polynomial degrees. What $\\rho$ do you need to get convergent results?\n",
    "\n",
    "+ Modify the code above so that you solve the problem with $X_1$ and $X_2$ that are Log-Normally distributed (choose your own mean and variance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 7: Dynamical System with Uncertain Parameters\n",
    "\n",
    "Consider the stochastic harmonic oscillator:\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "\\ddot{y} + \\omega^2(X)y &=& 0,\\\\\n",
    "y(0) &=& y_0(X),\\\\\n",
    "\\dot{y}(0) &=& v_0(X),\n",
    "\\end{array}\n",
    "$$\n",
    "where $X$ is a random variable with PDF $p(x)$.\n",
    "\n",
    "First, let's bring this to the form of a first order dynamical system.\n",
    "We set:\n",
    "$$\n",
    "y_1 = y,\n",
    "$$\n",
    "and \n",
    "$$\n",
    "y_2 = \\dot{y}.\n",
    "$$\n",
    "The dynamical system becomes:\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "\\dot{y}_1 &=& y_2,\\\\\n",
    "\\dot{y}_2 &=& -\\omega^2(X) y_1,\\\\\n",
    "y_1(0) &=& y_0(X),\\\\\n",
    "y_2(0) &=& v_0(X).\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Now, let $\\phi_1(x), \\phi_2(x),\\dots,\\phi_n(x)$ be the orthonormal polynomials of $p(x)$, i.e.\n",
    "$$\n",
    "\\langle \\phi_i, \\phi_j \\rangle = \\int \\phi_i(x) \\phi_j(x) p(x) dx = \\delta_{ij}.\n",
    "$$\n",
    "Expand the solution of the dynamical system in these polynomials:\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "y_1(t;x) &=& \\sum_{i=1}^n c_{1i}(t) \\phi_i(x),\\\\\n",
    "y_2(t;x) &=& \\sum_{i=1}^n c_{2i}(t) \\phi_i(x).\n",
    "\\end{array}\n",
    "$$\n",
    "We will derive the dynamical system that the $c_{ki}(t)$'s satisfy.\n",
    "\n",
    "Expand also, $\\omega(x), y_0(x)$ and $v_0(x)$:\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "\\omega(x) &=& \\sum_{i=1}^n \\omega_i \\phi_i(x),\\\\\n",
    "y_0(x) &=& \\sum_{i=1}^n y_{0i} \\phi_i(x),\\\\\n",
    "v_0(x) &=& \\sum_{i=1}^n v_{0i} \\phi_i(x).\n",
    "\\end{array}\n",
    "$$\n",
    "These coefficients, can all be found with a sparse grid quadrature before we even start:\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "\\omega_i &=& \\langle \\omega, \\phi_i\\rangle \\approx \\sum_{k=1}^{n_q}w_k\\omega(x_k)\\phi_i(x_k),\\\\\n",
    "y_{0i} &=& \\langle y_0, \\phi_i\\rangle \\approx \\sum_{k=1}^{n_q}w_k y_0(x_k)\\phi_i(x_k),\\\\\n",
    "v_{0i} &=& \\langle v_0, \\phi_i\\rangle \\approx \\sum_{k=1}^{n_q}w_k v_0(x_k)\\phi_i(x_k).\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Now back to the dynamical system.\n",
    "We have:\n",
    "$$\n",
    "\\dot{y}_1 = y_2 \\Rightarrow \\sum_{i=1}^n \\dot{c}_{1i} \\phi_i(x) = \\sum_{i=1}^n c_{2i}\\phi_i(x) \\Rightarrow \\dot{c}_{1i} = c_{2i},\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\dot{y}_2 = -\\omega^2(x) y_1 \\Rightarrow \\sum_{i=1}^n\\dot{c}_{2i}\\phi_i(x) = -\\left(\\sum_{i=1}^n \\omega_i \\phi_i(x)\\right)^2\\sum_{j=1}^nc_{1j}\\phi_j(x) = -\\sum_{i,j,r=1}^n \\omega_i\\omega_r c_{1j}\\phi_i(x)\\phi_r(x)\\phi_j(x). \n",
    "$$\n",
    "So, if we define:\n",
    "$$\n",
    "H_{ijr} = \\langle \\phi_i, \\phi_j,\\phi_r\\rangle \\approx \\sum_{k=1}^{n_q}w_k \\phi_i(x_k)\\phi_j(x_k)\\phi_r(x_k),\n",
    "$$\n",
    "we get:\n",
    "$$\n",
    "\\dot{c}_{2i} = -\\omega_i \\sum_{j,r=1}^n H_{ijr} \\omega_r c_{1j}.\n",
    "$$\n",
    "\n",
    "To wrap it up, the dynamical sytem we need to solve is:\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "\\dot{c}_{1i} &=& c_{2i},\\\\\n",
    "\\dot{c}_{2i} &=& -\\omega_i \\sum_{j,r=1}^n H_{ijr} \\omega_r c_{1j},\\\\\n",
    "c_{1i}(0) &=& y_{0i},\\\\\n",
    "c_{2i}(0) &=& v_{0i},\n",
    "\\end{array}\n",
    "$$\n",
    "for $i=1,\\dots,n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random variable\n",
    "X1 = st.norm()\n",
    "X2 = st.norm()\n",
    "X3 = st.norm()\n",
    "X = (X1, X2, X3)\n",
    "dim = len(X)\n",
    "\n",
    "# Modeling of the natural frequency:\n",
    "omega = lambda x: 2. * np.pi + x[:, 0]\n",
    "# Initial position\n",
    "y0 = lambda x: np.ones((x.shape[0],)) + 0.1 * x[:, 1]\n",
    "# Initial velocity\n",
    "v0 = lambda x: np.zeros((x.shape[0],)) + 0.1 * x[:, 2]\n",
    "\n",
    "# Construct the orthonormal polynomials\n",
    "degree = 5\n",
    "Phi_set = orthpol.ProductBasis(X, degree=degree, ncap=500)\n",
    "\n",
    "# Get a quadrature rule - we will talk about the quadrature rules in Lecture 17.\n",
    "Zq, v = design.sparse_grid(dim, 5, 'GH') # Gauss-Hermite which uses w(x) = e^{-x^T x} - need to scale:\n",
    "Xq = Zq * np.sqrt(2.)\n",
    "w = v / np.sqrt(np.pi ** dim)\n",
    "\n",
    "# The polynomials on the quadrature points\n",
    "phi_q = Phi_set(Xq)\n",
    "\n",
    "# Evaluate the matrix H\n",
    "H = np.einsum('k,ki,kj,kr->ijr', w, phi_q, phi_q, phi_q)\n",
    "\n",
    "# Evaluatae all needed coefficients\n",
    "omegas = np.einsum('k,k,ki->i', w, omega(Xq), phi_q)\n",
    "y0s = np.einsum('k,k,ki->i', w, y0(Xq), phi_q)\n",
    "v0s = np.einsum('k,k,ki->i', w, v0(Xq), phi_q)\n",
    "\n",
    "# Define the dynamical system\n",
    "n = Phi_set.num_output\n",
    "def c_rhs(c, t):\n",
    "    c1 = c[:n]\n",
    "    c2 = c[n:]\n",
    "    c1_rhs = c2\n",
    "    c2_rhs = -np.einsum('i,ijr,r,j->i', omegas, H, omegas, c1)\n",
    "    return np.hstack([c1_rhs, c2_rhs])\n",
    "\n",
    "c0 = np.hstack([y0s, v0s])\n",
    "\n",
    "# Solve the system\n",
    "t = np.linspace(0, 5, 500)\n",
    "c = scipy.integrate.odeint(c_rhs, c0, t)\n",
    "\n",
    "# Post proces the results\n",
    "# Coefficients for the position\n",
    "c1 = c[:, :n]\n",
    "# Coefficients for th velocity\n",
    "c2 = c[:, n:]\n",
    "# Mean position\n",
    "y1_m = c1[:, 0]\n",
    "# Mean velocity\n",
    "y2_m = c2[:, 0]\n",
    "# Variance of position\n",
    "y1_v = np.sum(c1[:, 1:] ** 2, axis=1)\n",
    "# Variance of velocity\n",
    "y2_v = np.sum(c2[:, 1:] ** 2, axis=1)\n",
    "# Lower and upper prediction intervals\n",
    "y1_s = np.sqrt(y1_v)\n",
    "y1_l = y1_m - 2. * y1_s\n",
    "y1_u = y1_m + 2. * y1_s\n",
    "y2_s = np.sqrt(y2_v)\n",
    "y2_l = y2_m - 2. * y2_s\n",
    "y2_u = y2_m + 2. * y2_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, y1_m)\n",
    "ax.fill_between(t, y1_l, y1_u, alpha=0.25)\n",
    "ax.set_xlabel('$t$')\n",
    "ax.set_ylabel('$y(t)$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, y2_m)\n",
    "ax.fill_between(t, y2_l, y2_u, alpha=0.25)\n",
    "ax.set_xlabel('$t$')\n",
    "ax.set_ylabel('$\\dot{y}(t)$');"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
