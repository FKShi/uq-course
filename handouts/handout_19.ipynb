{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 19 - Inverse Problems/Model Calibration: Classical Approaches\n",
    "\n",
    "## Objectives\n",
    "\n",
    "+ Appreciate the ubiquiteness of inverse problems through examples.\n",
    "+ Formulate inverse problems as optimization problems.\n",
    "+ Remember the adjoint method for dynamical systems.\n",
    "+ Demonstrate approach by applying it to the calibration of a reaction kinetics problem.\n",
    "+ Highlight the shortcomings of the classical approach to inverse problems.\n",
    "\n",
    "## Readings\n",
    "\n",
    "+ These notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import scipy.stats as st\n",
    "import scipy\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk')\n",
    "import design\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import orthpol "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Inverse Problems\n",
    "\n",
    "Suppose that you have a model (any model really) that predicts a quantity of interest.\n",
    "Let's assume that this model has parameters that you do not know.\n",
    "These parameters could be simple scalars (mass, spring constant, dumping coefficients, etc.) or it could be also be functions (initial conditions, boundary values, spatially distributed constitutive relations, etc.)\n",
    "In the case of the latter, we assume that you have already reduced the dimensionality of the parameterization with, for example, the Karhunen-Lo\\`eve expansion (see [Lecture 12](./handout_12.ipynb)).\n",
    "Let's denote all these parameters with the vector $x$.\n",
    "Assume that:\n",
    "$$\n",
    "x\\in\\mathcal{X} \\subset\\mathbb{R}^d.\n",
    "$$\n",
    "Now, let's say we perform an experiment that measures a *noisy* vector:\n",
    "$$\n",
    "y\\in\\mathcal{Y}\\subset \\mathbb{R}^m.\n",
    "$$\n",
    "Assume that, you can use your model *model* to predict $y$.\n",
    "It does not matter how complicated your model is.\n",
    "It could be a system of ordinary differential or partial differential equations, or something more complicated.\n",
    "If it predicts $y$, you can always think of it as a function from the unknown parameter space $\\mathcal{X}$ to the space of $y$'s, $\\mathcal{Y}\\subset\\mathbb{R}^m$.\n",
    "That is, you can think of it as giving rise to a function:\n",
    "$$\n",
    "f :\\mathcal{X} \\rightarrow \\mathcal{Y}.\n",
    "$$\n",
    "\n",
    "The **inverse problem**, otherwise known as the **model calibration** problem is to find the ``best`` $x\\in\\mathcal{X}$ so that:\n",
    "$$\n",
    "f(x) \\approx y.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulation of Inverse Problems as Optimization Problems\n",
    "Saying that $f(x)\\approx y$ is not an exact mathematical statement.\n",
    "What does it really mean for $f(x)$ to be close to $y$?\n",
    "To quantify this, let us introduce a *loss metric*:\n",
    "$$\n",
    "\\ell: \\mathcal{Y}\\times\\mathcal{Y}\\rightarrow \\mathbb{R},\n",
    "$$\n",
    "such that $\\ell(f(x),y)$ is how much our prediction is off if we chose the input $x\\in\\mathcal{X}$.\n",
    "Equiped with this loss metric, we can formulate the mathematical problem as:\n",
    "$$\n",
    "\\min_{x\\in\\mathcal{X}} \\ell(f(x),y).\n",
    "$$\n",
    "\n",
    "### The Square Loss\n",
    "The choice of the metric is somewhat subjective (it depends on what it means to be wrong in your problem).\n",
    "However, a very common assumption is that to take the *square loss*:\n",
    "$$\n",
    "\\ell(f(x), y) = \\frac{1}{2}\\parallel f(x) - y\\parallel_2^2 = \\frac{1}{2}\\sum_{i=1}^m\\left(f_i(x)-y_i\\right)^2.\n",
    "$$\n",
    "For this case, the inverse problem can be formulated as:\n",
    "$$\n",
    "\\min_{x\\in\\mathcal{X}}\\frac{1}{2}\\parallel f(x) - y\\parallel_2^2.\n",
    "$$\n",
    "\n",
    "### Solution Methodologies\n",
    "We basically have to solve an optimization problem.\n",
    "For the square loss function, if $f(x)$ is linear, then you get the classic least squares problem which has a known solution.\n",
    "Otherwise, you get what is known as *generalized least squares*.\n",
    "There are many algorithms that you could use this problem.\n",
    "Several are implemented in [scipy.optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html).\n",
    "If you are able to implement (and you should) your model as a simple python function, then you can use them.\n",
    "The absolutely, essential thing that you need to provide to these methods is the function they are optimizing, i.e.,\n",
    "$$\n",
    "L(x,y) = \\ell(f(x),y).\n",
    "$$\n",
    "\n",
    "### Numerical Estimation of Derivatives\n",
    "Most of the methods in [scipy.optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html) require the specification of the gradient:\n",
    "$$\n",
    "\\nabla L(x,y) = \\left(\\frac{\\partial L(x)}{\\partial x_1},\\dots,\\frac{\\partial L(x)}{\\partial x_d}\\right)\\in\\mathbb{R}^d.\n",
    "$$\n",
    "If you do not supply this function, then ``scipy`` will approximate it numerically with a [first order finite differences](https://en.wikipedia.org/wiki/Numerical_differentiation).\n",
    "The approximation they use is:\n",
    "$$\n",
    "\\frac{\\partial L(x,y)}{\\partial x_i} \\approx \\frac{L(x + he_i,y) - L(x,y)}{h},\n",
    "$$\n",
    "where $e_i\\in\\mathbb{R}^d$ is the $i$-th standard orthonormal unit vector of $\\mathbb{R}^d$ and $h$ is a small number, e.g., $h=10^{-6}$.\n",
    "This computational costs $d$ times the evaluation of the objective function.\n",
    "Thus, it is impractical for expensive models and high-dimensions.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Catalytic Conversion of Nitrate to Nitrogen\n",
    "\n",
    "This is Example 3.1 of [(Tsilifis, 2014)](http://arxiv.org/abs/1410.5522).\n",
    "\n",
    "Consider the catalytic\n",
    "conversion of nitrate ($\\mbox{NO}_3^-$) to nitrogen ($\\mbox{N}_2$) and other\n",
    "by-products by electrochemical means.\n",
    "The mechanism that is followed is complex and not well understood.\n",
    "The experiment of [(Katsounaros, 2012)](http://www.sciencedirect.com/science/article/pii/S0013468612005208) confirmed the\n",
    "production of nitrogen ($\\mbox{N}_2$), ammonia\n",
    "($\\mbox{NH}_3$), and nitrous oxide ($\\mbox{N}_2\\mbox{O}$) as final products\n",
    "of the reaction, as well as the intermediate production of nitrite ($\\mbox{NO}_2^-$).\n",
    "The data are reproduced in [Comma-separated values](https://en.wikipedia.org/wiki/Comma-separated_values) (CSV) and stored in\n",
    "[data/catalysis.csv](data/catalysis.csv).\n",
    "The time is measured in minutes and the conentrations are measured in $\\mbox{mmol}\\cdot\\mbox{L}^{-1}$.\n",
    "Let's load the data into this notebook using the [Pandas](http://pandas.pydata.org) Python module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If this fails, you haven't uploaded \"catalysis.csv\".\n",
    "# Repeat 11 of the instructions.\n",
    "import pandas as pd\n",
    "catalysis_data = pd.read_csv('catalysis.csv', index_col=0)\n",
    "catalysis_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the data using [Matplotlib](http://matplotlib.org):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catalysis_data.plot(style='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The theory of catalytic reactions guarantees that the total mass must be conserved.\n",
    "However, this is not the case in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catalysis_data.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This inconsistency suggests the existence of an intermediate unobserved reaction product X.\n",
    "[(Katsounaros, 2012)](http://www.sciencedirect.com/science/article/pii/S0013468612005208) suggested that the following reaction path shown in the following figure.\n",
    "\n",
    "![](scheme.png \"Reaction Scheme\")\n",
    "\n",
    "The dynamical system associated with the reaction is:\n",
    "$$\n",
    "\\begin{array}{cc}\n",
    "\\frac{d \\left[\\mbox{NO}_3^-\\right]}{dt} &= -k_1\\left[\\mbox{NO}_3^-\\right], \\\\\n",
    "\\frac{d\\left[\\mbox{NO}_2^-\\right]}{dt} &= k_1\\left[\\mbox{NO}_3^-\\right] - (k_2 + k_4 +\n",
    "k_5)[\\mbox{NO}_2^-], \\\\\n",
    "\\frac{d \\left[\\mbox{X}\\right]}{dt} &= k_2 \\left[\\mbox{NO}_2^-\\right] - k_3 [X],\\\\\n",
    "\\frac{d \\left[\\mbox{N}_2\\right]}{dt} &= k_3 \\left[\\mbox{X}\\right], \\\\\n",
    "\\frac{d \\left[\\mbox{NH}_3\\right]}{dt} &= k_4 \\left[\\mbox{NO}_2^-\\right],\\\\\n",
    "\\frac{d \\left[\\mbox{N}_2O\\right]}{dt} &= k_5 \\left[\\mbox{NO}_2^-\\right],\n",
    "\\end{array}\n",
    "$$\n",
    "where $[\\cdot]$ denotes the concentration of a quantity, and\n",
    "$k_i > 0$, $i=1,...5$ are the *kinetic rate constants*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulation of the Inverse Problem\n",
    "\n",
    "#### Step 1: Making our life easier by simplifying the notation\n",
    "Note that this is actually a linear system.\n",
    "To simplify our notation, let's define:\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "z_1 &:=& \\left[\\mbox{NO}_3^-\\right],\\\\\n",
    "z_2 &:=& \\left[\\mbox{NO}_2^-\\right],\\\\\n",
    "z_3 &:=& \\left[\\mbox{X}\\right],\\\\\n",
    "z_4 &:=& \\left[\\mbox{N}_2\\right],\\\\\n",
    "z_5 &:=& \\left[\\mbox{NH}_3\\right],\\\\\n",
    "z_6 &:=& \\left[\\mbox{N}_2O\\right],\n",
    "\\end{array}\n",
    "$$\n",
    "the vector:\n",
    "$$\n",
    "z = (z_1,z_2,z_3,z_4,z_5,z_6),\n",
    "$$\n",
    "and the matrix:\n",
    "$$\n",
    "A(k_1,\\dots,k_5) = \\left(\\begin{array}{cccccc}\n",
    "-k_1 & 0 & 0 & 0 & 0 & 0\\\\\n",
    "k_1 & -(k_2+k_4+k_5) & 0 & 0 & 0 & 0\\\\\n",
    "0 & k_2 & -k_3 & 0 & 0 & 0\\\\\n",
    "0 & 0 & k_3 & 0 & 0 & 0\\\\\n",
    "0 & k_4 & 0 & 0 & 0 & 0\\\\\n",
    "0 & k_5 & 0 & 0 & 0 & 0\n",
    "\\end{array}\\right)\\in\\mathbb{R}^{6\\times 6}.\n",
    "$$\n",
    "With these definitions, the dynamical system becomes:\n",
    "$$\n",
    "\\dot{z} = A(k_1,\\dots,k_5)z,\n",
    "$$\n",
    "with initial conditions\n",
    "$$\n",
    "z(0) = z_0 = (500, 0, 0, 0, 0, 0)\\in\\mathbb{R}^6,\n",
    "$$\n",
    "read directly from the experimental data.\n",
    "What we are definitely going to need is a solver for this system.\n",
    "That's easy.\n",
    "Let's denote the solution of the system at time $t$ by:\n",
    "$$\n",
    "z(t;k_1,\\dots,k_5).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Scale the unknown parameters to your best of your abilities\n",
    "The constraints you have on your parameters, the better.\n",
    "If you do have constraints, you would have to use constrained optimization algorithms.\n",
    "The way you scale things depend on the problem.\n",
    "Here we would think as follows:\n",
    "\n",
    "+ $k_i$ has units of inverse time. It is proparly appropriate to scale it with the total time which is 180 minutes.\n",
    "So, let's just multiply $k_i$ with 180. This makes the resulting variable dimensionless:\n",
    "$$\n",
    "\\hat{x}_i = 180k_i.\n",
    "$$\n",
    "\n",
    "+ $k_i$ is positive, therefore $\\hat{x_i}$ must be positive.\n",
    "So, let's just work with the logarithm of $\\hat{x_i}$:\n",
    "$$\n",
    "x_i = \\log \\hat{x_i} = \\log 180k_i.\n",
    "$$\n",
    "\n",
    "+ define the parameter vector:\n",
    "$$\n",
    "x = (x_1,\\dots,x_5)\\in\\mathcal{X} = \\mathbb{R}^5.\n",
    "$$\n",
    "\n",
    "From now on, we will write\n",
    "$$\n",
    "A = A(x),\n",
    "$$\n",
    "for the matrix of the dynamical system, and\n",
    "$$\n",
    "z = z(t;x),\n",
    "$$\n",
    "for the solution at $t$ given that the parameters are $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Making the connection between our model and the experimental measurements\n",
    "Our experimental data include measurements of everything except $z_3$ at times six (6) time instants:\n",
    "$$\n",
    "t_j = 30j\\;\\mbox{minutes},\n",
    "$$\n",
    "$j=1,\\dots,6$.\n",
    "\n",
    "Now, let $Y\\in\\mathbb{R}^{5\\times 6}$ be the experimental measurements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catalysis_data[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of the measurements as vector by flattening the matrix:\n",
    "$$\n",
    "y = \\operatorname{vec}(Y)\\in\\mathbb{R}^{30}.\n",
    "$$\n",
    "Note that ``vec`` is the vectorization operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the connection between the solution of the dynamical system $z(t,x)$ and the experimental data?\n",
    "It is as follows:\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "z_1(30j;x) &\\longrightarrow& Y_{j1},\\\\\n",
    "z_2(30j;x) &\\longrightarrow& Y_{j2},\\\\\n",
    "z_4(30j;x) &\\longrightarrow& Y_{j3},\\\\\n",
    "z_5(30j;x) &\\longrightarrow& Y_{j4},\\\\\n",
    "z_6(30j;x) &\\longrightarrow& Y_{j5},\n",
    "\\end{array}\n",
    "$$\n",
    "for $j=1,\\dots,6$.\n",
    "\n",
    "We are now ready to define a function:\n",
    "$$\n",
    "f:\\mathcal{X} \\rightarrow \\mathcal{Y}=\\mathbb{R}^{30}_+,\n",
    "$$\n",
    "as follows:\n",
    "+ Define the matrix function:\n",
    "$$\n",
    "F:\\mathcal{X} \\rightarrow \\mathbb{R}^{5\\times 6},\n",
    "$$\n",
    "by:\n",
    "$$\n",
    "\\begin{array}{ccccc}\n",
    "F_{j1}(x) &=& z_1(30j;x)&\\longrightarrow& Y_{j1},\\\\\n",
    "F_{j2}(x) &=& z_2(30j;x) &\\longrightarrow& Y_{j2},\\\\\n",
    "F_{j3}(x) &=& z_4(30j;x) &\\longrightarrow& Y_{j3},\\\\\n",
    "F_{j4}(x) &=& z_5(30j;x) &\\longrightarrow& Y_{j4},\\\\\n",
    "F_{j5}(x) &=& z_6(30j;x) &\\longrightarrow& Y_{j5},\n",
    "\\end{array}\n",
    "$$\n",
    "+ And flatten that function:\n",
    "$$\n",
    "f(x) = \\operatorname{vec}(F(x))\\in\\mathbb{R}^{30}.\n",
    "$$\n",
    "\n",
    "Now, we have made the connection with our theoretical formulation of inverse problems crystal clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Programming our solver and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.integrate\n",
    "\n",
    "def A(x):\n",
    "    \"\"\"\n",
    "    Return the matrix of the dynamical system.\n",
    "    \"\"\"\n",
    "    # Scale back to the k's\n",
    "    k = np.exp(x) / 180.\n",
    "    res = np.zeros((6,6))\n",
    "    res[0, 0] = -k[0]\n",
    "    res[1, 0] = k[0]\n",
    "    res[1, 1] = -(k[1] + k[3] + k[4])\n",
    "    res[2, 1] = k[1]\n",
    "    res[2, 2] = -k[2]\n",
    "    res[3, 2] = k[2]\n",
    "    res[4, 1] = k[4]\n",
    "    res[5, 1] = k[3]\n",
    "    return res\n",
    "    \n",
    "\n",
    "def g(z, t, x):\n",
    "    \"\"\"\n",
    "    The right hand side of the dynamical system.\n",
    "    \"\"\"\n",
    "    return np.dot(A(x), z)\n",
    "\n",
    "\n",
    "# The initial conditions\n",
    "z0 = np.array([500., 0., 0., 0., 0., 0.])\n",
    "\n",
    "\n",
    "# The times at which we need the solution (experimental times)\n",
    "t_exp = np.array([30. * j for j in range(1, 7)])\n",
    "\n",
    "# The experimental data as a matrix\n",
    "Y = catalysis_data[1:].get_values()\n",
    "\n",
    "# The experimental as a vector\n",
    "y = Y.flatten()\n",
    "\n",
    "# The full solution of the dynamical system\n",
    "def Z(x, t):\n",
    "    \"\"\"\n",
    "    Returns the solution for parameters x at times t.\n",
    "    \"\"\"\n",
    "    return scipy.integrate.odeint(g, z0, t, args=(x,))\n",
    "\n",
    "\n",
    "# The matrix function F (matches to Y)\n",
    "def F(x, t):\n",
    "    res = Z(x, t)\n",
    "    return np.hstack([res[:, :2], res[:, 3:]])\n",
    "    \n",
    "\n",
    "# The function f (matches to y)\n",
    "def f(x, t):\n",
    "    return F(x, t).flatten()\n",
    "\n",
    "\n",
    "# Finally, the loss function that we need to minimize over x:\n",
    "def L(x, t, y):\n",
    "    return 0.5 * np.sum((f(x, t) / 500. - y / 500.) ** 2) # We scale for numerical stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.optimize\n",
    "\n",
    "# Initial guess for x\n",
    "x0 = np.random.randn(5)\n",
    "#x0 = 10 * np.ones(5)\n",
    "\n",
    "# Optimize\n",
    "res = scipy.optimize.minimize(L, x0, args=(t_exp, y))\n",
    "\n",
    "print res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = res.x\n",
    "t = np.linspace(0, 180, 100)\n",
    "x1 = np.array([1.359, 1.657, 1.347, -.16, -1.01])\n",
    "Yp = Z(x, t)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "catalysis_data.plot(ax=ax, style='s')\n",
    "ax.plot(t, Yp[:, 0], color=sns.color_palette()[0], label='Model NO3-')\n",
    "ax.plot(t, Yp[:, 1], color=sns.color_palette()[1], label='Model NO2-')\n",
    "ax.plot(t, Yp[:, 2], color=sns.color_palette()[5], label='Model X')\n",
    "ax.plot(t, Yp[:, 3], color=sns.color_palette()[2], label='Model N2')\n",
    "ax.plot(t, Yp[:, 4], color=sns.color_palette()[3], label='Model NH3')\n",
    "ax.plot(t, Yp[:, 5], color=sns.color_palette()[4], label='Model N2O')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "+ Are you satisfied with the above model calibration?\n",
    "+ Rerun the code. Does the algorithm always work? Do you find exactly the same $x$?\n",
    "+ Start from an initial $x$ that is very far away from the zero. Like all 10's. What do you find?\n",
    "+ What is the average number of function evaluations that you need (see ``nfev`` as reported when we print ``res``)? Can this method be easily applied to expensive models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the Derivatives\n",
    "### Automatic Differentiation\n",
    "If you have access to the source code producing $L(x)$, including all details of your model $f(x)$, you could use one of the automatic differentiation methodologies.\n",
    "These see your source code as a mathematical function and they attemp to differntiate it directly using the chain rule.\n",
    "We are not using any of those because they do require a little bit of low-level coding.\n",
    "\n",
    "### Analytical Differentiation\n",
    "Let's use the chain rule to take the derivative of $L(x)$ with respect to $x_i$.\n",
    "We have:\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "\\frac{\\partial L(x,y)}{\\partial x_i} &=& \\frac{\\partial \\ell(f(x),y)}{\\partial x_i}\\\\\n",
    "&=& \\sum_{j=1}^m \\frac{\\partial \\ell(f(x),y)}{\\partial f_j}\\frac{\\partial f_j(x)}{\\partial x_i}.\n",
    "\\end{array}\n",
    "$$\n",
    "For the square loss, we get:\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "\\frac{\\partial L(x,y)}{\\partial x_i} &=& \\frac{\\partial \\frac{1}{2}\\parallel f(x)-y\\parallel_2^2}{\\partial x_i}\\\\\n",
    "&=& \\sum_{j=1}^m \\left(f_j(x)-y_j\\right)\\frac{\\partial f_j(x)}{\\partial x_i}.\n",
    "\\end{array}\n",
    "$$\n",
    "So, you see that what we really need is the **Jacobian matrix**:\n",
    "$$\n",
    "\\nabla f(x) = \\left(\n",
    "\\begin{array}{ccc}\n",
    "\\frac{\\partial f_1(x)}{\\partial x_1} & \\dots & \\frac{\\partial f_1(x)}{\\partial x_d}\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "\\frac{\\partial f_m(x)}{\\partial x_1} & \\dots & \\frac{\\partial f_m(x)}{\\partial x_d}\n",
    "\\end{array}\n",
    "\\right)\\in\\mathbb{R}^{m\\times d}.\n",
    "$$\n",
    "If your model is dynamical system (or a partial differential equation) you can use the method of adjoints to build it, see [Lecture 15](./hadnout_15.ipynb).\n",
    "We will give a brief reminder below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: The Adjoint of the Catalysis Problem\n",
    "\n",
    "We have already shown that the dynamical system corresponding to our catalysis model is:\n",
    "$$\n",
    "\\dot{z} = A(x)z,\n",
    "$$\n",
    "with\n",
    "$$\n",
    "z(0) = z_0.\n",
    "$$\n",
    "Let $z(t;x)$ denote the solution as a function of time and the parameters $x$.\n",
    "We will derive the a dynamical system that describes the evolution of: \n",
    "$$\n",
    "z_{,j} := \\frac{\\partial z}{\\partial x_j} = \\left(\\frac{\\partial z_1}{\\partial x_j},\\dots,\\frac{\\partial z_6}{\\partial x_j}\\right).\n",
    "$$\n",
    "We have from the chain rule:\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "\\dot{z_{,j}} &=& \\frac{\\partial\\dot{z}}{\\partial x_j}\\\\\n",
    "&=& \\frac{\\partial}{\\partial x_j}\\left(A(x)z\\right)\\\\\n",
    "&=& \\frac{\\partial A(x)}{\\partial x_i}z + A(x)\\frac{\\partial z}{\\partial x_j}\n",
    "\\end{array}\n",
    "$$\n",
    "So, for each $j=1,2,\\dots,d$, we need to solve the dynamical system:\n",
    "$$\n",
    "\\dot{z_{,j}} = \\frac{\\partial A(x)}{\\partial x_i}z + A(x)z_{,j},\n",
    "$$\n",
    "with initial conditions:\n",
    "$$\n",
    "z_{,j}(0) = \\frac{\\partial z_0}{\\partial x_j}.\n",
    "$$\n",
    "So, we see that we need to solve 6 additional dynamical systems that depend on the solution of the original one.\n",
    "They are completly independent.\n",
    "The implementation is a little bit involved. We are going to import the code from a source file.\n",
    "We are using the implementation from [(Tsilifis et al., 2015)](http://verification.asmedigitalcollection.asme.org/article.aspx?articleid=2534444).\n",
    "The files are in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from demos.catalysis import CatalysisModel\n",
    "solver = CatalysisModel()  # This works with the k's.\n",
    "\n",
    "# Let's define the loss function\n",
    "def L_with_jac(x, y):\n",
    "    k = np.exp(x) / 180.\n",
    "    sol = solver(k)\n",
    "    y = y / 500.\n",
    "    f = sol['f'][0][5:] / 500\n",
    "    dfdk = sol['f_grad'][0][5:, :] / 500.\n",
    "    dfdx = np.einsum('ij,j->ij', dfdk, k)\n",
    "    tmp = (f - y)\n",
    "    dLdx = np.einsum('ij,i->j', dfdx, tmp)\n",
    "    L = 0.5 * np.sum(tmp ** 2)\n",
    "    return L, dLdx\n",
    "\n",
    "# Never trust yourself when you are implementing derivatives.\n",
    "# It's always a good idea to test it.\n",
    "def f_test(x, y):\n",
    "    return L_with_jac(x, y)[0]\n",
    "\n",
    "print 'numerical derivative:'\n",
    "print scipy.optimize.approx_fprime(x, f_test, 1e-6, y)\n",
    "print 'analytical derivative:'\n",
    "print L_with_jac(x, y)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# They look fine, let's now solve the problem again using the adjoint derivative:\n",
    "# Initial guess for x\n",
    "x0 = np.random.randn(5)\n",
    "#x0 = 10 * np.ones(5)\n",
    "\n",
    "# Optimize\n",
    "res = scipy.optimize.minimize(L_with_jac, x0, jac=True, args=(y))\n",
    "\n",
    "print res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = res.x\n",
    "t = np.linspace(0, 180, 100)\n",
    "x1 = np.array([1.359, 1.657, 1.347, -.16, -1.01])\n",
    "Yp = Z(x, t)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "catalysis_data.plot(ax=ax, style='s')\n",
    "ax.plot(t, Yp[:, 0], color=sns.color_palette()[0], label='Model NO3-')\n",
    "ax.plot(t, Yp[:, 1], color=sns.color_palette()[1], label='Model NO2-')\n",
    "ax.plot(t, Yp[:, 2], color=sns.color_palette()[5], label='Model X')\n",
    "ax.plot(t, Yp[:, 3], color=sns.color_palette()[2], label='Model N2')\n",
    "ax.plot(t, Yp[:, 4], color=sns.color_palette()[3], label='Model NH3')\n",
    "ax.plot(t, Yp[:, 5], color=sns.color_palette()[4], label='Model N2O')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "+ Are you satisfied with the above model calibration?\n",
    "+ Does it payoff to get analytical derivatives?\n",
    "+ Ok. Derivatives are great. Can you think of way to get them using without messing too much with the solver? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortcomings of the Classic Approach\n",
    "\n",
    "There are several shorcomings of the classical approach to model calibration which we will remedy in the next lecture.\n",
    "Here we briefly mention some:\n",
    "\n",
    "+ The problems are ill-posed. Solutions may not exist. More than one solutions may exist.\n",
    "+ No apparent way to quantify uncertainties.\n",
    "+ No systematic way to account for prior knowledge."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
